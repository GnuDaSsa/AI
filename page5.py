import os
import time
import sys
from dotenv import load_dotenv
import openai
import streamlit as st
from PyPDF2 import PdfReader

# .env íŒŒì¼ì—ì„œ í™˜ê²½ë³€ìˆ˜ ë¡œë“œ
load_dotenv()

# ìµœì‹  openai ë°©ì‹: í´ë¼ì´ì–¸íŠ¸ ê°ì²´ ìƒì„±
api_key = os.getenv("OPENAI_API_KEY")
client = openai.OpenAI(api_key=api_key)

def typewriter_effect(text, speed=0.03):
    """
    íƒ€ì´í•‘ íš¨ê³¼ë¡œ í…ìŠ¤íŠ¸ë¥¼ ì¶œë ¥
    """
    for char in text:
        print(char, end='', flush=True)
        time.sleep(speed)
    print()

def generate_streaming_press_release(topic):
    """
    ìŠ¤íŠ¸ë¦¬ë° ë°©ì‹ìœ¼ë¡œ ë³´ë„ìë£Œ ìƒì„±
    """
    prompt = f"""
    ë‹¹ì‹ ì€ ì„±ë‚¨ì‹œì²­ í™ë³´ ë‹´ë‹¹ìì…ë‹ˆë‹¤. ì•„ë˜ ì£¼ì œë¡œ ê³µì‹ ë³´ë„ìë£Œë¥¼ ì‘ì„±í•˜ì„¸ìš”. 
    - ì£¼ì œ: {topic}
    - ë¶„ëŸ‰: 500ì ë‚´ì™¸
    - í˜•ì‹: ì œëª©, ë³¸ë¬¸(3~4ë¬¸ë‹¨)
    - ì–´íˆ¬: ê³µì‹ì ì´ê³  ì‹ ë¢°ê° ìˆê²Œ
    """
    
    try:
        # ìµœì‹  openai ë°©ì‹ (stream ì§€ì›)
        response = client.chat.completions.create(
            model="gpt-3.5-turbo",
            messages=[{"role": "user", "content": prompt}],
            max_tokens=800,
            temperature=0.7,
            stream=True
        )
        
        full_response = ""
        print("\n" + "="*50)
        print("AIê°€ ë³´ë„ìë£Œë¥¼ ì‘ì„± ì¤‘ì…ë‹ˆë‹¤...")
        print("="*50 + "\n")
        
        for chunk in response:
            if chunk.choices[0].delta.content:
                content = chunk.choices[0].delta.content
                full_response += content
                # ì‹¤ì‹œê°„ìœ¼ë¡œ íƒ€ì´í•‘ íš¨ê³¼
                typewriter_effect(content, speed=0.01)
        
        return full_response
        
    except Exception as e:
        return f"ì˜¤ë¥˜ ë°œìƒ: {e}"

def generate_with_loading_animation(topic):
    """
    ë¡œë”© ì• ë‹ˆë©”ì´ì…˜ê³¼ í•¨ê»˜ ë³´ë„ìë£Œ ìƒì„±
    """
    loading_chars = ["â ‹", "â ™", "â ¹", "â ¸", "â ¼", "â ´", "â ¦", "â §", "â ‡", "â "]
    
    print("\nAIê°€ ë³´ë„ìë£Œë¥¼ ìƒì„± ì¤‘ì…ë‹ˆë‹¤...")
    
    # ë¡œë”© ì• ë‹ˆë©”ì´ì…˜
    for i in range(10):
        print(f"\r{loading_chars[i]} AIê°€ ìƒê° ì¤‘... {i*10}%", end='', flush=True)
        time.sleep(0.2)
    
    print("\n\n" + "="*50)
    print("ë³´ë„ìë£Œ ìƒì„± ì™„ë£Œ!")
    print("="*50 + "\n")
    
    # ì‹¤ì œ ìƒì„±
    return generate_streaming_press_release(topic)

def interactive_press_generator():
    """
    ì¸í„°ë™í‹°ë¸Œí•œ ë³´ë„ìë£Œ ìƒì„±ê¸°
    """
    print("ğŸ¯ ì„±ë‚¨ì‹œ ë³´ë„ìë£Œ ì‹¤ì‹œê°„ ìƒì„±ê¸°")
    print("="*50)
    
    while True:
        print("\nğŸ“ ë³´ë„ìë£Œ ì£¼ì œ/í‚¤ì›Œë“œë¥¼ ì…ë ¥í•˜ì„¸ìš” (ì¢…ë£Œ: 'quit' ë˜ëŠ” 'exit'):")
        topic = input("> ").strip()
        
        if topic.lower() in ['quit', 'exit', 'ì¢…ë£Œ']:
            print("\nğŸ‘‹ ë³´ë„ìë£Œ ìƒì„±ê¸°ë¥¼ ì¢…ë£Œí•©ë‹ˆë‹¤.")
            break
        
        if not topic:
            print("âŒ ì£¼ì œë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.")
            continue
        
        # ìƒì„± ì‹œì‘
        result = generate_with_loading_animation(topic)
        
        # ê²°ê³¼ ìš”ì•½
        print("\n" + "="*50)
        print("ğŸ“Š ìƒì„± ì™„ë£Œ!")
        print(f"ğŸ“ ì£¼ì œ: {topic}")
        print(f"ğŸ“ ê¸€ì ìˆ˜: {len(result)}ì")
        print("="*50)
        
        # ê³„ì†í• ì§€ ë¬»ê¸°
        print("\nğŸ”„ ë‹¤ë¥¸ ì£¼ì œë¡œ ë³´ë„ìë£Œë¥¼ ìƒì„±í•˜ì‹œê² ìŠµë‹ˆê¹Œ? (y/n):")
        continue_choice = input("> ").strip().lower()
        
        if continue_choice not in ['y', 'yes', 'ë„¤', 'ì˜ˆ']:
            print("\nğŸ‘‹ ë³´ë„ìë£Œ ìƒì„±ê¸°ë¥¼ ì¢…ë£Œí•©ë‹ˆë‹¤.")
            break

def extract_pdf_text(file):
    try:
        reader = PdfReader(file)
        text = ""
        for page in reader.pages:
            text += page.extract_text() or ""
        return text.strip()
    except Exception as e:
        return f"PDF ì¶”ì¶œ ì˜¤ë¥˜: {e}"

def summarize_text(text, client, api_key):
    # ë„ˆë¬´ ê¸´ ê²½ìš° ì•ë¶€ë¶„ë§Œ ì‚¬ìš© (í† í° ì œí•œ)
    if len(text) > 3000:
        text = text[:3000]
    prompt = f"""
    ì•„ë˜ì˜ PDF ë‚´ìš©ì„ 5ë¬¸ì¥ ì´ë‚´ë¡œ ìš”ì•½í•´ì¤˜.
    ---
    {text}
    ---
    """
    try:
        response = client.chat.completions.create(
            model="gpt-3.5-turbo",
            messages=[{"role": "user", "content": prompt}],
            max_tokens=400,
            temperature=0.3,
            stream=False
        )
        return response.choices[0].message.content.strip()
    except Exception as e:
        return f"ìš”ì•½ ì˜¤ë¥˜: {e}"

def run():
    st.title("ì„±ë‚¨ì‹œ ë³´ë„ìë£Œ ìƒì„±ê¸° (AI)")
    st.markdown("OpenAI APIë¥¼ í™œìš©í•´ ì£¼ì œì— ë§ëŠ” ê³µì‹ ë³´ë„ìë£Œë¥¼ ìƒì„±í•©ë‹ˆë‹¤.")
    topic = st.text_input("ğŸ“ ë³´ë„ìë£Œ ì£¼ì œ/í‚¤ì›Œë“œ ì…ë ¥")
    length = st.radio("ì›í•˜ëŠ” ë³´ë„ìë£Œ ë¶„ëŸ‰(ê¸€ì ìˆ˜)", [500, 700, 900, 1100], index=0, horizontal=True)
    pdf_file = st.file_uploader("ì°¸ê³ í•  PDF íŒŒì¼ ì—…ë¡œë“œ (ì„ íƒ)", type=["pdf"])
    pdf_text = ""
    pdf_summary = ""
    api_key = os.getenv("OPENAI_API_KEY")
    if not api_key or api_key == "sk-your-api-key-here":
        st.error("OPENAI_API_KEY í™˜ê²½ë³€ìˆ˜ê°€ ì„¤ì •ë˜ì–´ ìˆì§€ ì•ŠìŠµë‹ˆë‹¤. .env íŒŒì¼ ë˜ëŠ” í™˜ê²½ë³€ìˆ˜ë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”.")
        return
    client = openai.OpenAI(api_key=api_key)
    if pdf_file:
        with st.spinner("PDFì—ì„œ í…ìŠ¤íŠ¸ ì¶”ì¶œ ì¤‘..."):
            pdf_text = extract_pdf_text(pdf_file)
            if pdf_text and not pdf_text.startswith("PDF ì¶”ì¶œ ì˜¤ë¥˜"):
                pdf_summary = summarize_text(pdf_text, client, api_key)
                st.success("PDF ìš”ì•½ ê²°ê³¼:")
                st.info(pdf_summary)
            else:
                st.error(pdf_text)
    if st.button("ë³´ë„ìë£Œ ìƒì„±í•˜ê¸°"):
        if not topic:
            st.warning("ì£¼ì œë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.")
        else:
            with st.spinner("AIê°€ ë³´ë„ìë£Œë¥¼ ìƒì„± ì¤‘ì…ë‹ˆë‹¤..."):
                try:
                    prompt = f"""
                    ë‹¹ì‹ ì€ ì„±ë‚¨ì‹œì²­ í™ë³´ ë‹´ë‹¹ìì…ë‹ˆë‹¤. ì•„ë˜ ì£¼ì œë¡œ ê³µì‹ ë³´ë„ìë£Œë¥¼ ì‘ì„±í•˜ì„¸ìš”. 
                    - ì£¼ì œ: {topic}
                    - ë¶„ëŸ‰: ìµœì†Œ {length-50}ì ì´ìƒ, {length}ìì— ìµœëŒ€í•œ ê°€ê¹ê²Œ ì‘ì„±
                    - í˜•ì‹: ì œëª©, ë³¸ë¬¸(3~4ë¬¸ë‹¨)
                    - ì–´íˆ¬: ê³µì‹ì ì´ê³  ì‹ ë¢°ê° ìˆê²Œ
                    - ê¸€ì ìˆ˜ê°€ ë¶€ì¡±í•˜ë©´ ë‚´ìš©ì„ ë” ì¶”ê°€í•´ ì£¼ì„¸ìš”.
                    """
                    if pdf_summary:
                        prompt += f"\n- ì°¸ê³ ìë£Œ: {pdf_summary}"
                    response = client.chat.completions.create(
                        model="gpt-3.5-turbo",
                        messages=[{"role": "user", "content": prompt}],
                        max_tokens=2500,  # ë„‰ë„‰í•˜ê²Œ ê³ ì •
                        temperature=0.7,
                        stream=False
                    )
                    result = response.choices[0].message.content
                    st.success("ìƒì„± ì™„ë£Œ!")
                    st.markdown(f"**ì£¼ì œ:** {topic}")
                    st.markdown(f"**ê¸€ì ìˆ˜:** {len(result)}ì")
                    st.markdown("---")
                    st.write(result)
                except Exception as e:
                    st.error(f"ì˜¤ë¥˜ ë°œìƒ: {e}")

if __name__ == "__main__":
    if not api_key or api_key == "sk-your-api-key-here":
        print("âŒ OPENAI_API_KEY í™˜ê²½ë³€ìˆ˜ë¥¼ ì„¤ì •í•´ì£¼ì„¸ìš”.")
        print("ğŸ’¡ .env íŒŒì¼ì—ì„œ ì‹¤ì œ API í‚¤ë¡œ ë³€ê²½í•˜ì„¸ìš”.")
        exit(1)
    
    try:
        run()
    except KeyboardInterrupt:
        print("\n\nğŸ‘‹ ì‚¬ìš©ìê°€ ì¤‘ë‹¨í–ˆìŠµë‹ˆë‹¤. í”„ë¡œê·¸ë¨ì„ ì¢…ë£Œí•©ë‹ˆë‹¤.")
    except Exception as e:
        print(f"\nâŒ ì˜¤ë¥˜ ë°œìƒ: {e}")
        print("ğŸ”§ í”„ë¡œê·¸ë¨ì„ ë‹¤ì‹œ ì‹œì‘í•´ì£¼ì„¸ìš”.")